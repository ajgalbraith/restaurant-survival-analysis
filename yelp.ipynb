{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2023.8.0)\n",
      "Requirement already satisfied: click>=8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (23.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask) (3.15.0)\n",
      "Requirement already satisfied: locket in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from partd>=1.2.0->dask) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: distributed in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2023.8.0)\n",
      "Requirement already satisfied: click>=8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (2.2.1)\n",
      "Requirement already satisfied: dask==2023.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (2023.8.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (23.0)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (5.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (6.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (2.0.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (0.12.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (6.1)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (1.26.16)\n",
      "Requirement already satisfied: zict>=2.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask==2023.8.0->distributed) (2023.6.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask==2023.8.0->distributed) (1.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from dask==2023.8.0->distributed) (6.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask==2023.8.0->distributed) (3.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting AST\n",
      "  Using cached AST-0.0.2.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-bj5m43ew/ast_b30ffe33fef245758edcef33d03b587f/setup.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     README = codecs.open(os.path.join(here, 'AST/README'), encoding='utf8').read()\n",
      "  \u001b[31m   \u001b[0m   File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/codecs.py\", line 906, in open\n",
      "  \u001b[31m   \u001b[0m     file = builtins.open(filename, mode, buffering)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-install-bj5m43ew/ast_b30ffe33fef245758edcef33d03b587f/AST/README'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dask\n",
    "%pip install distributed\n",
    "%pip install AST\n",
    "%pip install tqdm\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client\n",
    "\n",
    "MINIMUM_REVIEWS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_restaurants = (\n",
    "    dd.read_csv(\"./data/yelp-restaurants.csv/0.part\", dtype={\"postal_code\": \"object\"})\n",
    "    .compute()\n",
    "    \n",
    ")\n",
    "yelp_restaurants = yelp_restaurants.drop(columns=yelp_restaurants.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def attribute_mapping(restaurants):\n",
    "    restaurants = restaurants\n",
    "    # map attributes to columns  \n",
    "    rows = list(restaurants.index)\n",
    "\n",
    "    attributes = pd.DataFrame()\n",
    "    \n",
    "    for row in tqdm(rows):\n",
    "        d = restaurants.loc[row, \"attributes\"]\n",
    "        attr = pd.DataFrame(eval(d), index=[row])\n",
    "        # extra_layer_unfiltered = ['BusinessParking','GoodForMeal','Ambience']\n",
    "        # extra_layer = [e for e in extra_layer_unfiltered if e in attr.columns]\n",
    "        extra_layer = [\"BusinessParking\", \"GoodForMeal\", \"Ambience\"]\n",
    "\n",
    "        for item in extra_layer:\n",
    "            try:\n",
    "                s = attr.loc[row, item]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if type(s) == pd._libs.missing.NAType:\n",
    "                continue\n",
    "            col = pd.DataFrame(ast.literal_eval(s), index=[row])\n",
    "            attr = pd.concat([attr, col], axis=1)\n",
    "\n",
    "        attr.drop(columns=extra_layer, inplace=True, errors=\"ignore\")\n",
    "        attributes = pd.concat([attributes, attr], axis=0)\n",
    "\n",
    "    # feature reduction\n",
    "\n",
    "    # Missing Value Ratio: if more than 20% is null -> drop\n",
    "    null_count = attributes.isna().sum()\n",
    "    attributes.dropna(thresh=len(attributes) * 0.8, axis=1, inplace=True)\n",
    "\n",
    "    # replace\n",
    "    attributes.replace(\n",
    "        to_replace={\"False\": \"0\", \"True\": \"1\", \"None\": pd.NA}, inplace=True\n",
    "    )\n",
    "    cols_to_process = [\"Alcohol\", \"NoiseLevel\", \"RestaurantsAttire\", \"WiFi\"]\n",
    "    cols_to_int = [\n",
    "        \"BikeParking\",\n",
    "        \"BusinessAcceptsCreditCards\",\n",
    "        \"Caters\",\n",
    "        \"GoodForKids\",\n",
    "        \"HasTV\",\n",
    "        \"OutdoorSeating\",\n",
    "        \"RestaurantsDelivery\",\n",
    "        \"RestaurantsGoodForGroups\",\n",
    "        \"RestaurantsPriceRange2\",\n",
    "        \"RestaurantsReservations\",\n",
    "        \"RestaurantsTakeOut\",\n",
    "        \"garage\",\n",
    "        \"street\",\n",
    "        \"validated\",\n",
    "        \"lot\",\n",
    "        \"valet\",\n",
    "        \"romantic\",\n",
    "        \"intimate\",\n",
    "        \"touristy\",\n",
    "        \"hipster\",\n",
    "        \"divey\",\n",
    "        \"classy\",\n",
    "        \"trendy\",\n",
    "        \"upscale\",\n",
    "        \"casual\",\n",
    "    ]\n",
    "\n",
    "    for col in cols_to_int:\n",
    "        try:\n",
    "            attributes[col] = attributes[col].astype(int, errors=\"ignore\")\n",
    "        except KeyError:\n",
    "            continue\n",
    "    attributes.Alcohol[attributes.Alcohol == \"u'none'\"] = 0\n",
    "    attributes.Alcohol[attributes.Alcohol == \"'none'\"] = 0\n",
    "    attributes.Alcohol[attributes.Alcohol == \"u'beer_and_wine'\"] = 1\n",
    "    attributes.Alcohol[attributes.Alcohol == \"'beer_and_wine'\"] = 1\n",
    "    attributes.Alcohol[attributes.Alcohol == \"u'full_bar'\"] = 2\n",
    "    attributes.Alcohol[attributes.Alcohol == \"'full_bar'\"] = 2\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"u'quiet'\"] = 0\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"'quiet'\"] = 0\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"u'average'\"] = 1\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"'average'\"] = 1\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"u'loud'\"] = 2\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"'loud'\"] = 2\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"u'very_loud'\"] = 3\n",
    "    attributes.NoiseLevel[attributes.NoiseLevel == \"'very_loud'\"] = 3\n",
    "    attributes.RestaurantsAttire[attributes.RestaurantsAttire == \"u'casual'\"] = 0\n",
    "    attributes.RestaurantsAttire[attributes.RestaurantsAttire == \"'casual'\"] = 0\n",
    "    attributes.RestaurantsAttire[attributes.RestaurantsAttire == \"u'dressy'\"] = 1\n",
    "    attributes.RestaurantsAttire[attributes.RestaurantsAttire == \"'dressy'\"] = 1\n",
    "    attributes.RestaurantsAttire[attributes.RestaurantsAttire == \"u'formal'\"] = 2\n",
    "    attributes.RestaurantsAttire[attributes.RestaurantsAttire == \"'formal'\"] = 2\n",
    "    attributes.WiFi[attributes.WiFi == \"u'free'\"] = \"free\"\n",
    "    attributes.WiFi[attributes.WiFi == \"u'no'\"] = \"no\"\n",
    "    attributes.WiFi[attributes.WiFi == \"u'paid'\"] = \"paid\"\n",
    "\n",
    "    attributes.WiFi[attributes.WiFi == \"'free'\"] = \"free\"\n",
    "    attributes.WiFi[attributes.WiFi == \"'no'\"] = \"no\"\n",
    "    attributes.WiFi[attributes.WiFi == \"'paid'\"] = \"paid\"\n",
    "\n",
    "    attributes = dd.from_pandas(attributes, npartitions=100)\n",
    "    return attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_yelp_restaurants(restaurants):\n",
    "    # filter out non-restaurants\n",
    "    restaurants = restaurants[\n",
    "        restaurants[\"categories\"].notna()\n",
    "    ]  # filter out null attributes\n",
    "    searchfor = [\"food\", \"restaurant\", \"dessert\"]\n",
    "    restaurants = restaurants[\n",
    "        restaurants[\"categories\"].str.contains(\"|\".join(searchfor), case=False)\n",
    "    ]\n",
    "    # filter out restaurants with less than MINIMUM_REVIEWS\n",
    "    restaurants = restaurants[restaurants[\"review_count\"] >= MINIMUM_REVIEWS]\n",
    "    restaurants.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # filter out null attributes\n",
    "    restaurants = restaurants[restaurants[\"attributes\"].notnull()]\n",
    "\n",
    "    # add attributes\n",
    "    attributes = attribute_mapping(restaurants).compute()\n",
    "    restaurants = restaurants.merge(attributes, left_index=True, right_index=True)\n",
    "\n",
    "    restaurants.fillna(restaurants.mode().iloc[0], inplace=True)\n",
    "\n",
    "    # fix wifi\n",
    "    wifi = dd.get_dummies(restaurants[\"WiFi\"])\n",
    "    restaurants = dd.concat([restaurants, wifi], axis=1)\n",
    "    restaurants = restaurants.drop(columns=\"WiFi\")\n",
    "    attributes = attributes.drop(columns=\"WiFi\")\n",
    "    restaurants = restaurants.compute()\n",
    "\n",
    "    return restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy = yelp_restaurants.copy(deep=True)\n",
    "# results = preprocess_yelp_restaurants(yelp_restaurants)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews = dd.read_csv(\n",
    "    \"./data/yelp-reviews.csv/0.part\", dtype={\"postal_code\": \"object\"}\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_yelp_reviews(reviews):\n",
    "    reviews = reviews.set_index(\"business_id\")\n",
    "    reviews = reviews[[\"stars\", \"useful\", \"funny\", \"cool\"]]\n",
    "    reviews = reviews.groupby(\"business_id\").mean()\n",
    "    reviews = reviews.rename(columns={\"stars\": \"avg_stars\"})\n",
    "    reviews.compute()\n",
    "    return reviews\n",
    "\n",
    "\n",
    "# preprocess_yelp_reviews(yelp_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_yelp(restaurants, reviews):\n",
    "    df = restaurants.merge(\n",
    "        reviews, on=\"business_id\", how=\"left\", suffixes=(\"\", \"_calculated\")\n",
    "    ).compute()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152639/3454836335.py:8: PerformanceWarning: Falling back on a non-pyarrow code path which may decrease performance.\n",
      "  restaurants[\"categories\"].str.contains(\"|\".join(searchfor), case=False)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12496/12496 [02:26<00:00, 85.51it/s]\n",
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 17.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'compute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_152639/4216298359.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_yelp_restaurants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myelp_restaurants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_yelp_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myelp_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_yelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_152639/3089303821.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(reviews)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"useful\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cool\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"stars\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"avg_stars\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'compute'"
     ]
    }
   ],
   "source": [
    "rest = preprocess_yelp_restaurants(yelp_restaurants)\n",
    "rev = preprocess_yelp_reviews(yelp_reviews)\n",
    "preprocessed = preprocess_yelp(rest,rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(preprocessed\u001b[39m.\u001b[39mcolumns)\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39mis_open\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mis_open\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m features\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "features = (list(preprocessed.columns).remove(\"is_open\"))\n",
    "label = 'is_open'\n",
    "features\n",
    "\n",
    "df = restaurants[['stars','stars_calculated','review_count','RestaurantsPriceRange2',label]]\n",
    "sns.set(rc = {'figure.figsize':(10,7)})\n",
    "sns.heatmap(df.corr(),annot=True)\n",
    "\n",
    "X = restaurants[features]\n",
    "y = restaurants[label]\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "#feature selection\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(X, y)\n",
    "filter = selector.get_support()\n",
    "top_5_features = X.columns[filter]\n",
    "\n",
    "print(\"Best 5 features:\")\n",
    "print(top_5_features)\n",
    "\n",
    "# PCA\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "zscoredData = stats.zscore(X)\n",
    "pca = PCA().fit(zscoredData)\n",
    "eigVals = pca.explained_variance_\n",
    "loadings = pca.components_*-1\n",
    "rotated = pca.fit_transform(zscoredData)*-1\n",
    "\n",
    "#scree plot\n",
    "numClasses = X.shape[1]\n",
    "x = np.linspace(1,numClasses,numClasses)\n",
    "plt.bar(x, eigVals, color='gray')\n",
    "plt.plot([0,numClasses],[1,1],color='orange') # Orange Kaiser criterion line for the fox\n",
    "plt.xlabel('Principal component')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1234)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.30, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,prob)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "sns.lineplot(x=fpr, y=tpr, marker = 'o')\n",
    "plt.title(\"Receiver operating characteristic (ROC) curve\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "#plt.legend(['RF with 20 estimators', 'RF with 100 estimators'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(fpr, tpr)\n",
    "accuracy_score(y_test, pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "pd.DataFrame(\n",
    "confusion_matrix(y_test, pred, labels=[True, False]),\n",
    "columns=['Predicted: Open', 'Predicted: Closed'],\n",
    "index=['Actual: Open', 'Actual: Closed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [(\"DT\", DecisionTreeClassifier()),\n",
    "              (\"RF\", RandomForestClassifier()),\n",
    "              (\"GBDT\", GradientBoostingClassifier()),\n",
    "              (\"LR\", LogisticRegression())\n",
    "             ]\n",
    "stacking_model = StackingClassifier(estimators=estimators,cv=5,passthrough=False)\n",
    "params = {\n",
    "    \"DT__max_depth\": [8, 16],\n",
    "    \"GBDT__n_estimators\":[100,300],\n",
    "    \"RF__min_samples_split\":[2,5,10]\n",
    "}\n",
    "\n",
    "stack_grid = GridSearchCV(stacking_model, params, cv=3, verbose=4, scoring='accuracy', refit=True, n_jobs=-1)\n",
    "stack_grid.fit(X_train, y_train)\n",
    "print(stack_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = [(\"DT\", DecisionTreeClassifier(max_depth=stack_grid.best_params_['DT__max_depth'])),\n",
    "              (\"RF\", RandomForestClassifier(min_samples_split=stack_grid.best_params_['RF__min_samples_split'])),\n",
    "              (\"GBDT\", GradientBoostingClassifier(n_estimators=stack_grid.best_params_['GBDT__n_estimators'])),\n",
    "              (\"LR\", LogisticRegression())\n",
    "             ]\n",
    "\n",
    "best_stacking_model = StackingClassifier(estimators=best_estimators,cv=5,passthrough=False)\n",
    "best_stacking_model.fit(X_train,y_train)\n",
    "ensemble_pred = best_stacking_model.predict(X_test)\n",
    "ensemble_prob = best_stacking_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test,ensemble_prob)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "sns.lineplot(x=fpr, y=tpr, marker = 'o')\n",
    "plt.title(\"Receiver operating characteristic (ROC) curve\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "#plt.legend(['RF with 20 estimators', 'RF with 100 estimators'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(fpr, tpr)\n",
    "accuracy_score(y_test, ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "pd.DataFrame(\n",
    "confusion_matrix(y_test, ensemble_pred, labels=[True, False]),\n",
    "columns=['Predicted: Open', 'Predicted: Closed'],\n",
    "index=['Actual: Open', 'Actual: Closed'])\n",
    "\n",
    "precision_ensemble, recall_ensemble, thresholds_ensemble = precision_recall_curve(y_test,ensemble_prob)\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test,prob)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "sns.lineplot (x=recall_ensemble, y=precision_ensemble, color = 'green')\n",
    "sns.lineplot (x=recall_rf, y=precision_rf, color = 'red')\n",
    "\n",
    "\n",
    "plt.title('Precision-recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
